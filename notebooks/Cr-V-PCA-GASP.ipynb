{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b586af",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f38e74",
   "metadata": {},
   "source": [
    "La validation croisée est une technique d'apprentissage automatique utilisée pour évaluer les performances d'un modèle en le formant sur une partie des données disponibles et en le testant sur une autre partie. C'est un moyen de valider les performances du modèle en utilisant plusieurs \"plis\" de données de formation et de test, plutôt qu'un seul ensemble de formation et de test.\n",
    "\n",
    "Il existe plusieurs types de techniques de validation croisée, notamment :\n",
    "\n",
    " - La validation croisée K-fold : Il s'agit de la technique la plus couramment utilisée, où les données sont divisées en k plis de taille égale. Le modèle est entraîné sur k-1 plis et testé sur le pli restant, et ce processus est répété k fois, un pli différent étant utilisé comme ensemble de test à chaque fois. La moyenne de la mesure de performance est ensuite calculée sur l'ensemble des k itérations.\n",
    " \n",
    " - Validation croisée k-fold stratifiée : Cette technique est similaire à la validation croisée k-fold, mais elle garantit que la distribution des classes des données est préservée à travers chaque pli. Cette technique est utile lorsque la distribution des classes est déséquilibrée, car elle permet d'éviter les biais dans l'évaluation du modèle.\n",
    " \n",
    " - Validation croisée leave-p-out : Cette technique est similaire à la validation croisée k-fold, mais elle vous permet de spécifier le nombre d'échantillons à laisser de côté comme ensemble de test à chaque itération.\n",
    "\n",
    " - Validation croisée avec exclusion : Il s'agit d'un cas particulier de la validation croisée leave-p-out, où p est fixé à 1. Cela signifie qu'à chaque itération, un seul échantillon est laissé de côté comme ensemble de test, et le modèle est entraîné sur les échantillons restants.\n",
    " \n",
    "\n",
    "La validation croisée est une étape importante du processus d'apprentissage automatique, car elle permet d'éviter le surajustement et fournit une estimation plus précise des performances du modèle sur des données non vues. Elle est généralement utilisée en conjonction avec l'optimisation des hyperparamètres, car elle vous permet de régler les hyperparamètres de votre modèle et de sélectionner la meilleure combinaison d'hyperparamètres en fonction des performances du modèle sur les données de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd97e3a",
   "metadata": {},
   "source": [
    "### Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5373935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diakite/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/diakite/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris \n",
    "\n",
    "# Load the data\n",
    "iris = load_iris() \n",
    "X, y = iris.data, iris.target \n",
    "\n",
    "# Create the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Create the k-fold cross-validator\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store the accuracy scores\n",
    "accuracy_scores = []\n",
    "\n",
    "# Iterate over the folds\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Add the accuracy score to the list\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "# Calculate the mean accuracy score\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "print(f\"Mean accuracy: {mean_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22dbea9",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb45203",
   "metadata": {},
   "source": [
    "L'analyse en composantes principales, ou ACP, est une technique statistique permettant de convertir des données de haute dimension en données de basse dimension en sélectionnant les caractéristiques les plus importantes qui capturent le maximum d'informations sur l'ensemble de données. Les caractéristiques sont sélectionnées sur la base de la variance qu'elles provoquent dans le résultat. La caractéristique qui cause la plus grande variance est la première composante principale. La caractéristique qui est responsable de la deuxième plus grande variance est considérée comme la deuxième composante principale, et ainsi de suite. Il est important de mentionner que les composantes principales n'ont aucune corrélation entre elles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b7b77",
   "metadata": {},
   "source": [
    "### Avantages de l'ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9584c423",
   "metadata": {},
   "source": [
    "La réduction de la dimensionnalité avec l'ACP présente deux avantages principaux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606987eb",
   "metadata": {},
   "source": [
    " - Le temps d'apprentissage des algorithmes est considérablement réduit avec un nombre réduit de caractéristiques.\n",
    " \n",
    " - Il n'est pas toujours possible d'analyser des données en haute dimension. Par exemple, s'il y a 100 caractéristiques dans un ensemble de données. Le nombre total de diagrammes de dispersion nécessaires pour visualiser les données serait de 100(100-1)2 = 4950. En pratique, il n'est pas possible d'analyser les données de cette manière."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bc96db",
   "metadata": {},
   "source": [
    "### Normalisation des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7a6699",
   "metadata": {},
   "source": [
    "Il est impératif de mentionner qu'un ensemble de variables doit être normalisé avant d'appliquer l'ACP. Par exemple, si un ensemble de caractéristiques contient des données exprimées en unités de kilogrammes, d'années-lumière ou de millions, l'échelle de variance est énorme dans l'ensemble d'apprentissage. Si l'ACP est appliquée à un tel ensemble de caractéristiques, les charges résultantes pour les caractéristiques à forte variance seront également importantes. Par conséquent, les composantes principales seront biaisées en faveur des caractéristiques à forte variance, ce qui entraînera des résultats erronés.\n",
    "\n",
    "Enfin, le dernier point à retenir avant de commencer le codage est que l'ACP est une technique statistique et ne peut être appliquée qu'à des données numériques. Par conséquent, les caractéristiques catégorielles doivent être converties en caractéristiques numériques avant de pouvoir appliquer l'ACP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e09a7",
   "metadata": {},
   "source": [
    "### Mise en œuvre de l'ACP avec Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc5620",
   "metadata": {},
   "source": [
    "Dans cette section, nous allons mettre en œuvre l'ACP à l'aide de la bibliothèque Scikit-Learn de Python. Nous suivrons le pipeline classique de l'apprentissage automatique : nous commencerons par importer des bibliothèques et des ensembles de données, nous effectuerons une analyse exploratoire des données et un prétraitement, et enfin nous entraînerons nos modèles, nous ferons des prédictions et nous évaluerons la précision. La seule étape supplémentaire consistera à effectuer une ACP pour déterminer le nombre optimal de caractéristiques avant de former nos modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b38902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e18005",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "dataset = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5701d5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=55ab6d9e-d22f-45d7-bcaa-3f7dd4f5c61f style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('55ab6d9e-d22f-45d7-bcaa-3f7dd4f5c61f').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91a802",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7529e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/pj4f3ws14fl09641x7pq364w0000gn/T/ipykernel_88040/2098761270.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X = dataset.drop('Class', 1)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.drop('Class', 1)\n",
    "y = dataset['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ae83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cadca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8877bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8089ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17a78626",
   "metadata": {},
   "source": [
    "### Applying PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2dbabb",
   "metadata": {},
   "source": [
    "Il suffit de trois lignes de code pour effectuer une ACP à l'aide de la bibliothèque Scikit-Learn de Python. La classe PCA est utilisée à cet effet. L'ACP dépend uniquement de l'ensemble des variables et non des données d'étiquetage. Par conséquent, l'ACP peut être considérée comme une technique d'apprentissage automatique non supervisée.\n",
    "\n",
    "\n",
    "La réalisation de l'ACP à l'aide de Scikit-Learn est un processus en deux étapes :\n",
    "\n",
    " - Initialiser la classe PCA en passant le nombre de composants au constructeur\n",
    " \n",
    " - Appelez les méthodes *fit* puis transform en leur transmettant l'ensemble des variables. La méthode *transform* renvoie le nombre spécifié de composantes principales.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be392b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c316e",
   "metadata": {},
   "source": [
    "La classe PCA contient *explained_variance_ratio_* qui renvoie la variance causée par chacune des composantes principales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee3e0b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72226528, 0.23974795, 0.03338117, 0.0046056 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be650071",
   "metadata": {},
   "source": [
    "On peut voir que la première composante principale est responsable de 72,22% de la variance. De même, la deuxième composante principale est responsable de 23,9 % de la variance de l'ensemble de données. Collectivement, nous pouvons dire que (72,22 + 23,9) 96,21% de l'information de classification contenue dans l'ensemble de caractéristiques est capturée par les deux premières composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8883d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a0ecf5",
   "metadata": {},
   "source": [
    "### Training and Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b4c399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b3f94",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45ce65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1  5]]\n",
      "Accuracy  : 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy  :',  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e93f8ea",
   "metadata": {},
   "source": [
    "### Results with 2 and 3 Principal Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da688c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd96ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "530521a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0  9  4]\n",
      " [ 0  2  4]]\n",
      "Accuracy : 0.8\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy :',  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a2fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For 3 composantes, faites le en exercice (creer une fonction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
