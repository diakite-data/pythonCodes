{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation de Spark sur Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Java 8 or Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour installer Apache Spark sur Windows, vous aurez besoin de Java 8 ou de la dernière version ; téléchargez donc la version Java depuis [Oracle](https://www.oracle.com/java/technologies/downloads/#java8)\n",
    " et installez-la sur votre système. Si vous voulez OpenJDK, vous pouvez le télécharger [ici](https://adoptopenjdk.net/) .\n",
    "\n",
    "Après le téléchargement, double-cliquez sur le fichier **.exe (jdk-8u201-windows-x64.exe)** afin de l'installer sur votre système Windows. Choisissez un répertoire personnalisé ou conservez l'emplacement par défaut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation d'Apache Spark sous Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Spark se présente sous la forme d'un fichier tar/zip compressé. L'installation sur Windows n'est donc pas très compliquée puisqu'il suffit de télécharger et de dé-tarer le fichier. Téléchargez Apache Spark en accédant à la page de téléchargement de [Spark](https://spark.apache.org/downloads.html) et sélectionnez le lien \"Download Spark (point 3 de la capture d'écran ci-dessous)\".\n",
    "\n",
    "Si vous souhaitez utiliser une autre version de Spark & Hadoop, sélectionnez celle que vous voulez dans la liste déroulante ; le lien au point 3 change en fonction de la version sélectionnée et vous fournit un lien actualisé à télécharger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![download-page-spark](./sparkk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après le téléchargement, décompactez le fichier binaire à l'aide de 7zip ou de tout autre utilitaire zip pour extraire le fichier zip et copiez le répertoire extrait, **spark-3.0.0-bin-hadoop2.7** , dans le répertoire *c:\\apps\\opt\\spark-3.0.0-bin-hadoop2.7*.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables d'environnement Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après l'installation de Java et Apache Spark sur Windows, définissez les variables d'environnement **JAVA_HOME**, **SPARK_HOME**, **HADOOP_HOME** et **PATH**. Si vous savez comment définir les variables d'environnement sous Windows, ajoutez ce qui suit.\n",
    "\n",
    "```\n",
    "JAVA_HOME = C:\\Program Files\\Java\\jdk1.8.0_201\n",
    "PATH = %PATH%;%JAVA_HOME%\n",
    "\n",
    "SPARK_HOME  = C:\\apps\\opt\\spark-3.0.0-bin-hadoop2.7\n",
    "HADOOP_HOME = C:\\apps\\opt\\spark-3.0.0-bin-hadoop2.7\n",
    "PATH=%PATH%;%SPARK_HOME%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suivez les étapes ci-dessous si vous ne savez pas comment ajouter ou modifier des variables d'environnement sous Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. Ouvrez la fenêtre Variables d'environnement du système et sélectionnez Variables d'environnement\n",
    "\n",
    "![download-page-spark](./spark2.png)\n",
    "\n",
    "- 2. Dans l'écran de variable d'environnement suivant, ajoutez *SPARK_HOME*, *HADOOP_HOME*, *JAVA_HOME* en sélectionnant l'option Nouveau\n",
    "\n",
    "![download-page-spark](./spark3.png)\n",
    "\n",
    "- 3. Cela ouvre la fenêtre Nouvelles variables utilisateur dans laquelle vous pouvez saisir le nom et la valeur de la variable.\n",
    "\n",
    "- 4. Modifiez maintenant la variable *PATH*\n",
    "\n",
    "![download-page-spark](./spark4.png)\n",
    "\n",
    "- 5. Ajoutez l'emplacement du bin Spark, Java et Hadoop en sélectionnant l'option Nouveau\n",
    "\n",
    "![download-page-spark](./spark5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark with winutils.exe on Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beaucoup de débutants pensent qu'Apache Spark a besoin d'un cluster Hadoop installé pour fonctionner mais ce n'est pas vrai, Spark peut fonctionner sur AWS en utilisant S3, Azure en utilisant le stockage blob sans Hadoop et HDFS, e.t.c...\n",
    "\n",
    "Pour exécuter Apache Spark sur Windows, vous avez besoin de *winutils.exe*, car il utilise des opérations d'accès aux fichiers de type POSIX dans Windows en utilisant l'API de Windows.\n",
    "\n",
    "*winutils.exe* permet à Spark d'utiliser des services spécifiques à Windows, y compris l'exécution de commandes shell dans un environnement Windows.\n",
    "\n",
    "Téléchargez [winutils.exe](https://github.com/steveloughran/winutils/blob/master/hadoop-2.7.1/bin/winutils.exe) pour Hadoop 2.7 et copiez-le dans le dossier **%SPARK_HOME%\\bin**. Les Winutils sont différents pour chaque version d'Hadoop ; téléchargez donc la bonne version en fonction de votre distribution Spark vs Hadoop sur https://github.com/steveloughran/winutils ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apache Spark shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark-shell est un utilitaire CLI fourni avec la distribution Apache Spark. Ouvrez l'invite de commande, allez dans *cd %SPARK_HOME%/bin* et tapez la commande spark-shell pour exécuter Apache Spark shell. Vous devriez voir quelque chose comme ci-dessous (ignorez l'erreur que vous voyez à la fin).\n",
    "\n",
    "![download-page-spark](./spark7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark-shell crée également une interface web de contexte Spark et par défaut, elle peut être accessible à partir de http://localhost:4041."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration de Spark avec Scala et exécution dans IntelliJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi de nombreux autres IDE, **IntelliJ IDEA** est l'un des plus utilisés pour exécuter une application Spark écrite en Scala, en raison de sa bonne complétion de code Scala. Dans cet article, je vais expliquer comment configurer l'exécution d'une application Apache Spark écrite en Scala en utilisant *Sbt* avec *IntelliJ IDEA*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install JDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous savez peut-être que Spark a été créé en langage Scala et que Scala est un langage JVM qui a besoin de JVM pour fonctionner. Par conséquent, pour compiler et exécuter l'application Spark, vous devez avoir Java installé sur votre système.\n",
    "\n",
    "Téléchargez et installez Java 8 ou plus sur [Oracle.com](https://www.java.com/en/download/) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration d'IntelliJ IDEA pour Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des ingénieurs Spark utilisent IntelliJ IDEA pour exécuter des applications Spark écrites en Scala en raison de sa bonne compatibilité avec Scala. Il est donc préférable d'avoir un environnement de développement configuré en utilisant IntelliJ.\n",
    "\n",
    "IntelliJ IDEA existe en édition communautaire et ultime. Afin d'exécuter l'application Spark écrite en Scala, l'édition communautaire est juste suffisante pour nous, alors téléchargez IntelliJ IDEA [édition communautaire](https://www.jetbrains.com/idea/download/#section=windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Vous pouvez télécharger le programme d'installation Windows (.exe) ou un fichier zip compressé (.zip) selon votre convenance.\n",
    " \n",
    " ![download-page-spark](./spark8.png)\n",
    " \n",
    " - Maintenant, décompressons en utilisant Winzip, 7-Zip, ou tout autre extrait de zip que vous avez.\n",
    " \n",
    " ![download-page-spark](./spark9.png)\n",
    "\n",
    " - Déplacez le dossier extrait de Downloads vers votre dossier de travail. Dans mon cas, je l'ai déplacé dans le dossier *c:\\apps\\*.\n",
    " \n",
    " - Lancez IntelliJ IDE en exécutant idea64.exe depuis C:\\apps\\ideaIC-2020.2.1.win\\bin\\idea64.exe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un projet Scala dans IntelliJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
