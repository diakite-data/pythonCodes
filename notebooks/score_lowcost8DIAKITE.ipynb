{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align: center;\" markdown = \"1\"> DIAKITE MAMADOU YOUSSOUF </h1>\n",
    "<h3 style = \"text-align: center;\" markdown = \"2\"> Master 2 BIG DATA -- DATA SCIENCE </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: center;\" markdown = \"2\"> SPARK </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove(\"metastore_db/db.lck\")\n",
    "    os.remove(\"metastore_db/dbex.lck\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def build_spark_session(app_name, memory='4g', executors=4):\n",
    "    return SparkSession.builder\\\n",
    "                      .appName(app_name)\\\n",
    "                      .config('spark.executor.memory', memory)\\\n",
    "                      .config('spark.executor.instances', executors)\\\n",
    "                      .getOrCreate()\n",
    "\n",
    "spark_session = build_spark_session(app_name='ok-google')\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l'objectif est de predire l'appentence des clients a des transport lowcoast.\n",
    "Pour cela, nous utiliserons la librairie Ml de spark"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "perimetre: représente les identifaints des clients accessible à l'étude.\n",
    "histo_client: represente l'historique des données clients sur une période donnée\n",
    "histo_train: represente l'historique des données de commandes trains.\n",
    "histo_lowcost: represente l'historique des données de client lowcost (défini avec le métier).\n",
    "visites: représente l'historique des données de navigation des clients sur le site."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 - lire les fichiers de données\n",
    "2 - identifier les variables continues et transformer leurs modalités en double.\n",
    "3 - joindre les differentes sources de données en se basant sur les données du périmètre (tous les individus du périmèetre devront apparaitre dans la jointure avec des valeurs NULL si nécessaire pour les colonnes en provenance d'autres sources).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - joindre les dataframe sur la clé ID_CLIENT en concervant tous les clients du périmètre.\n",
    "2 - compter le nombre de ID_CLIENT et vérifier qu'il correspond aux nombre d'ID_CLIENT dans la variable perimètre.\n",
    "3 - Caster les variables continues en double et sauvergarder alors le df obtenu dans le repertoire data sur le cluster.\n",
    "4 - Pour les variables catégorielles, créer une nouvelle variable qui prend la modalité de la variable courante si elle existe et \"NA\" sinon.\n",
    "5- Verifier la cohérence des variables continue. Par exemple pour une variable comme age mettre à -1 tous les ages <0 ou>120ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading files (reading files)\n",
    "\n",
    "perimetre = spark_session.read.csv(\"data_clients/sample_perimetre.csv\", header=True)\n",
    "histo_client_raw = spark_session.read.csv(\"data_clients/sample_histo_client.csv\", header=True)\n",
    "histo_train_raw = spark_session.read.csv(\"data_clients/sample_histo_train.csv\", header=True)\n",
    "histo_lowcost_raw = spark_session.read.csv(\"data_clients/sample_histo_lowcost.csv\", header=True)\n",
    "visites_raw = spark_session.read.csv(\"data_clients/sample_visites.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID_CLIENT: string (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- ID_CLIENT: string (nullable = true)\n",
      " |-- anciennete: string (nullable = true)\n",
      " |-- recence_cmd: string (nullable = true)\n",
      " |-- AGE: string (nullable = true)\n",
      " |-- LBL_STATUT_CLT: string (nullable = true)\n",
      " |-- LBL_GEO_AIR: string (nullable = true)\n",
      " |-- LBL_GRP_SEGMENT_NL: string (nullable = true)\n",
      " |-- LBL_SEG_COMPORTEMENTAL: string (nullable = true)\n",
      " |-- LBL_GEO_TRAIN: string (nullable = true)\n",
      " |-- LBL_SEGMENT_ANTICIPATION: string (nullable = true)\n",
      " |-- FLG_CMD_CARTE_1225: string (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- ID_CLIENT: string (nullable = true)\n",
      " |-- flg_cmd_lowcost: string (nullable = true)\n",
      " |-- flg_track_nl_lowcost: string (nullable = true)\n",
      " |-- flg_track_nl: string (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- ID_CLIENT: string (nullable = true)\n",
      " |-- days_since_last_visit: string (nullable = true)\n",
      " |-- tx_conversion: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Identify continuous variables\n",
    "\n",
    "print(perimetre.printSchema())\n",
    "print(histo_client_raw.printSchema())\n",
    "print(histo_lowcost_raw.printSchema())\n",
    "print(visites_raw.printSchema())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecrire une fonction pour transformer \n",
    "#### les features quantitatives (\"anciennete\", \"recence_cmd\", \"AGE\", etc..) en float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform quantitatives features in double \n",
    "\n",
    "client_cols_to_keep = [\"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
    "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
    "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225']\n",
    "\n",
    "def cast_columns_of_df(df, cols_to_cast, col_to_keep, cast_type='double'):\n",
    "    \"\"\"cast continuous columns into double since all columns are \"\"\"\n",
    "    return df.select(col_to_keep + [(df[feature].cast(cast_type))\n",
    "                    for feature in cols_to_cast if 'ID_CLIENT' not in feature])\n",
    "\n",
    "histo_train = cast_columns_of_df(histo_train_raw, histo_train_raw.columns,\n",
    "                                 [\"ID_CLIENT\"], cast_type='double')\n",
    "\n",
    "histo_lowcost = cast_columns_of_df(histo_lowcost_raw, histo_lowcost_raw.columns,\n",
    "                                 [\"ID_CLIENT\"], cast_type='double')\n",
    "\n",
    "visites = cast_columns_of_df(visites_raw, visites_raw.columns,\n",
    "                             [\"ID_CLIENT\"], cast_type='double')\n",
    "\n",
    "histo_client = cast_columns_of_df(histo_client_raw,\n",
    "                                  [\"anciennete\", \"recence_cmd\", \"AGE\"],\n",
    "                                  client_cols_to_keep,\n",
    "                                 cast_type='double')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1084217"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firsly we count the number of row of perimetre\n",
    "perimetre.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We join sequentially file perimetre with the others files \n",
    "per11 = perimetre.join(histo_client, on = ['ID_CLIENT'], how = 'left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "per12 = per11.join(histo_lowcost, on = ['ID_CLIENT'], how = 'left_outer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "per13 = per12.join(histo_train, on = ['ID_CLIENT'], how = 'left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "per14 = per13.join(visites, on = ['ID_CLIENT'], how = 'left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1084217"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check the number of row of our final dataset\n",
    "# It equals to the number of row of perimetre\n",
    "per14.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelles sont les differentes modalites de la feature LBL_STATUT_CLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LBL_STATUT_CLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moyen moins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non present dans la base a cette date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nouveau prospect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prospect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tres petit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Petit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inactif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nouveau actif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tres grand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Moyen plus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           LBL_STATUT_CLT\n",
       "0                             Moyen moins\n",
       "1   Non present dans la base a cette date\n",
       "2                        Nouveau prospect\n",
       "3                                Prospect\n",
       "4                              Tres petit\n",
       "5                                    None\n",
       "6                                   Petit\n",
       "7                                 Inactif\n",
       "8                           Nouveau actif\n",
       "9                                   Grand\n",
       "10                             Tres grand\n",
       "11                             Moyen plus"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Differentes modalités de la variable LBL_STATUT_CLT\n",
    "per14.select('LBL_STATUT_CLT').distinct().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelles sont les features avec valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with missing data\n",
    "\n",
    "from pyspark.sql.functions import col,sum\n",
    "# We can count the missing values by summing the boolean output of the isNull() method\n",
    "\n",
    "def check_missing_values(df) :\n",
    "\n",
    "    return df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CLIENT</th>\n",
       "      <th>LBL_STATUT_CLT</th>\n",
       "      <th>LBL_GEO_AIR</th>\n",
       "      <th>LBL_SEG_COMPORTEMENTAL</th>\n",
       "      <th>LBL_GEO_TRAIN</th>\n",
       "      <th>LBL_GRP_SEGMENT_NL</th>\n",
       "      <th>LBL_SEGMENT_ANTICIPATION</th>\n",
       "      <th>FLG_CMD_CARTE_1225</th>\n",
       "      <th>anciennete</th>\n",
       "      <th>recence_cmd</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_od</th>\n",
       "      <th>mean_nb_passagers</th>\n",
       "      <th>mean_duree_voyage</th>\n",
       "      <th>mean_mt_voyage</th>\n",
       "      <th>mean_tarif_loisir</th>\n",
       "      <th>mean_classe_1</th>\n",
       "      <th>mean_pointe</th>\n",
       "      <th>mean_depart_we</th>\n",
       "      <th>days_since_last_visit</th>\n",
       "      <th>tx_conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78998</td>\n",
       "      <td>162977</td>\n",
       "      <td>155160</td>\n",
       "      <td>163010</td>\n",
       "      <td>79522</td>\n",
       "      <td>157822</td>\n",
       "      <td>10283</td>\n",
       "      <td>55</td>\n",
       "      <td>1484</td>\n",
       "      <td>...</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>62370</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>49927</td>\n",
       "      <td>220485</td>\n",
       "      <td>220485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_CLIENT  LBL_STATUT_CLT  LBL_GEO_AIR  LBL_SEG_COMPORTEMENTAL  \\\n",
       "0          0           78998       162977                  155160   \n",
       "\n",
       "   LBL_GEO_TRAIN  LBL_GRP_SEGMENT_NL  LBL_SEGMENT_ANTICIPATION  \\\n",
       "0         163010               79522                    157822   \n",
       "\n",
       "   FLG_CMD_CARTE_1225  anciennete  recence_cmd  ...  nb_od  mean_nb_passagers  \\\n",
       "0               10283          55         1484  ...  49927              49927   \n",
       "\n",
       "   mean_duree_voyage  mean_mt_voyage  mean_tarif_loisir  mean_classe_1  \\\n",
       "0              49927           49927              62370          49927   \n",
       "\n",
       "   mean_pointe  mean_depart_we  days_since_last_visit  tx_conversion  \n",
       "0        49927           49927                 220485         220485  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_missing_values(per14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that almost all variables have missing except \"ID_CLIENT\" and \"LBL_STATUT_CLT\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CLIENT', 'string'),\n",
       " ('LBL_STATUT_CLT', 'string'),\n",
       " ('LBL_GEO_AIR', 'string'),\n",
       " ('LBL_SEG_COMPORTEMENTAL', 'string'),\n",
       " ('LBL_GEO_TRAIN', 'string'),\n",
       " ('LBL_GRP_SEGMENT_NL', 'string'),\n",
       " ('LBL_SEGMENT_ANTICIPATION', 'string'),\n",
       " ('FLG_CMD_CARTE_1225', 'string'),\n",
       " ('anciennete', 'double'),\n",
       " ('recence_cmd', 'double'),\n",
       " ('AGE', 'double'),\n",
       " ('flg_cmd_lowcost', 'double'),\n",
       " ('flg_track_nl_lowcost', 'double'),\n",
       " ('flg_track_nl', 'double'),\n",
       " ('nb_od', 'double'),\n",
       " ('mean_nb_passagers', 'double'),\n",
       " ('mean_duree_voyage', 'double'),\n",
       " ('mean_mt_voyage', 'double'),\n",
       " ('mean_tarif_loisir', 'double'),\n",
       " ('mean_classe_1', 'double'),\n",
       " ('mean_pointe', 'double'),\n",
       " ('mean_depart_we', 'double'),\n",
       " ('days_since_last_visit', 'double'),\n",
       " ('tx_conversion', 'double')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of quantitatives and qualitatives features\n",
    "per14.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8 quantitatives features and 16 qualitatives features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacer les valeurs manquantes par -1 pour toutes les features qualitatives et par la moyenne\n",
    "#### pour toutes les features quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we select continuous variables\n",
    "\n",
    "def select_continous_features(df) :\n",
    "    LL = []\n",
    "    for i in df.dtypes :\n",
    "        if i[1] == 'double' :\n",
    "            LL.append(i[0])\n",
    "    return LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns = select_continous_features(per14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove 'flg_cmd_lowcost' from our list our continuous values\n",
    "del(continuous_columns[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anciennete',\n",
       " 'recence_cmd',\n",
       " 'AGE',\n",
       " 'flg_track_nl_lowcost',\n",
       " 'flg_track_nl',\n",
       " 'nb_od',\n",
       " 'mean_nb_passagers',\n",
       " 'mean_duree_voyage',\n",
       " 'mean_mt_voyage',\n",
       " 'mean_tarif_loisir',\n",
       " 'mean_classe_1',\n",
       " 'mean_pointe',\n",
       " 'mean_depart_we',\n",
       " 'days_since_last_visit',\n",
       " 'tx_conversion']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input missing value \n",
    "# for qualitative variable input with -1\n",
    "# for quantitative with mean \n",
    "from pyspark.sql.functions import col,sum\n",
    "\n",
    "def missing_values_input(df):\n",
    "    features_quali = ['flg_cmd_lowcost', \"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
    "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
    "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225']\n",
    "\n",
    "    df2 = df.select([f.when(df[feature].isNotNull(), df[feature])\\\n",
    "                .otherwise('-1').alias(feature) for feature in features_quali]\\\n",
    "               + [f.when(df[feature].isNotNull(), df[feature])\\\n",
    "                 .otherwise(df.agg({feature :'mean'}).toPandas().values[0][0]).alias(feature)\n",
    "                  for feature in continuous_columns])\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "per17 = missing_values_input(per14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flg_cmd_lowcost</th>\n",
       "      <th>ID_CLIENT</th>\n",
       "      <th>LBL_STATUT_CLT</th>\n",
       "      <th>LBL_GEO_AIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>000843db32fbaecfbb047ca0bb04b1f9f4d9425a</td>\n",
       "      <td>Grand</td>\n",
       "      <td>Aéroports de Paris Orly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>001338752ea32d9de129c8f8bdf3e2224cf0bd71</td>\n",
       "      <td>Grand</td>\n",
       "      <td>Aéroport de Marseille Provence  (MRS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flg_cmd_lowcost                                 ID_CLIENT LBL_STATUT_CLT  \\\n",
       "0              -1  000843db32fbaecfbb047ca0bb04b1f9f4d9425a          Grand   \n",
       "1              -1  001338752ea32d9de129c8f8bdf3e2224cf0bd71          Grand   \n",
       "\n",
       "                             LBL_GEO_AIR  \n",
       "0                Aéroports de Paris Orly  \n",
       "1  Aéroport de Marseille Provence  (MRS)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now per17 is our new dataset\n",
    "per17.toPandas().iloc[0:2,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- flg_cmd_lowcost: string (nullable = true)\n",
      " |-- ID_CLIENT: string (nullable = true)\n",
      " |-- LBL_STATUT_CLT: string (nullable = true)\n",
      " |-- LBL_GEO_AIR: string (nullable = true)\n",
      " |-- LBL_SEG_COMPORTEMENTAL: string (nullable = true)\n",
      " |-- LBL_GEO_TRAIN: string (nullable = true)\n",
      " |-- LBL_GRP_SEGMENT_NL: string (nullable = true)\n",
      " |-- LBL_SEGMENT_ANTICIPATION: string (nullable = true)\n",
      " |-- FLG_CMD_CARTE_1225: string (nullable = true)\n",
      " |-- anciennete: double (nullable = true)\n",
      " |-- recence_cmd: double (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- flg_track_nl_lowcost: double (nullable = true)\n",
      " |-- flg_track_nl: double (nullable = true)\n",
      " |-- nb_od: double (nullable = true)\n",
      " |-- mean_nb_passagers: double (nullable = true)\n",
      " |-- mean_duree_voyage: double (nullable = true)\n",
      " |-- mean_mt_voyage: double (nullable = true)\n",
      " |-- mean_tarif_loisir: double (nullable = true)\n",
      " |-- mean_classe_1: double (nullable = true)\n",
      " |-- mean_pointe: double (nullable = true)\n",
      " |-- mean_depart_we: double (nullable = true)\n",
      " |-- days_since_last_visit: double (nullable = true)\n",
      " |-- tx_conversion: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "per17.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelles sont les differentes valeurs de notre label : flg_cmd_lowcost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flg_cmd_lowcost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flg_cmd_lowcost\n",
       "0             1.0\n",
       "1              -1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per17.select('flg_cmd_lowcost').distinct().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features engineering et modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_df(df):\n",
    "    ds = df.select('ID_CLIENT',\n",
    "    f.when(df.LBL_GEO_TRAIN.isin(['Toulouse', 'Lille', 'Dijon',\n",
    "                                  'Lyon', 'Marseille', 'Paris',\n",
    "                                  'Nice', 'Limoges','Rouen','Rennes',\n",
    "                                  'Montpellier', 'Bordeaux', 'Metz',\n",
    "                                  'Strasbourg']), df.LBL_GEO_TRAIN)\\\n",
    "               .otherwise('na').alias('geo_train'),\n",
    "    f.when(df.LBL_GEO_AIR.isin(['Aéroports de Paris Orly',\n",
    "                                'Aéroport de Bâle-Mulhouse / Bassel',\n",
    "                                'Aéroport Lille Lesquin', 'Aéroport de Rennes',\n",
    "                                'Aéroport de Nantes Atlantique',\n",
    "                                'Aéroport de Marseille Provence  (MRS)', \n",
    "                                'Aéroport de Bordeaux Mérignac',\n",
    "                                'Aéroports de Paris Roissy-Charles-de Gaulle', \n",
    "                                \"Aéroport de Nice Côte d'Azur\",\n",
    "                                'Aéroport de Strasbourg',\n",
    "                                'Aéroport de Lyon - Saint Exupéry', \n",
    "                                'Aéroport de Toulouse Blagnac']), df.LBL_GEO_AIR)\\\n",
    "               .otherwise('na').alias('geo_air'),\n",
    "    f.when(df.FLG_CMD_CARTE_1225 == '1', '1')\\\n",
    "                   .otherwise('0').alias('cc_jeunes'),\n",
    "    f.when(df.LBL_STATUT_CLT.isin(['Tres grand', 'Nouveau actif',\n",
    "                                   'Moyen moins', ' Prospect', ' Petit',\n",
    "                                   'Inactif', 'Tres petit',\n",
    "                                   'Nouveau prospect', 'Moyen plus',\n",
    "                                   'Grand']), df.LBL_STATUT_CLT)\\\n",
    "                   .otherwise('na').alias('segt_rfm'),\n",
    "    f.when(df.LBL_SEGMENT_ANTICIPATION.isin(['Peu Anticipateur', 'Tres Anticipateur',\n",
    "                                             'Anticipateur', 'Mixte', 'Non Anticipateur',\n",
    "                                             'Non Defini']), df.LBL_SEGMENT_ANTICIPATION)\\\n",
    "                   .otherwise('na').alias('segt_anticipation'),\n",
    "    f.when(df.LBL_SEG_COMPORTEMENTAL.isin(['Mono-commande',\n",
    "                                           'Comportement Pro',\n",
    "                                           'Exclusifs Agence', \n",
    "                                           'Anticipateurs Methodiques',\n",
    "                                           'Chasseurs Bons Plans', \n",
    "                                           'Rythmes scolaires', 'Nouveaux',\n",
    "                                           'Sans contraintes']),\n",
    "           df.LBL_SEG_COMPORTEMENTAL).otherwise('na').alias('segt_comportemental'), \n",
    "    f.when(df.LBL_GRP_SEGMENT_NL.isin(['Endormi', 'Spectateur', 'Acteur',\n",
    "                                       'Eteint', 'Non defini']),\n",
    "           df.LBL_GRP_SEGMENT_NL).otherwise('na').alias('segt_nl'),\n",
    "    f.when(((df.AGE > 0) & (df.AGE < 100)), df.AGE)\\\n",
    "                   .otherwise(-1).alias('age'),\n",
    "    f.when(df.recence_cmd >= 0, df.recence_cmd)\\\n",
    "                   .otherwise(-1).alias('recence_cmd'),\n",
    "    f.when(((df.mean_duree_voyage > 0) & (df.mean_duree_voyage < 750)),\n",
    "           df.mean_duree_voyage).otherwise(-1).alias('mean_duree_voyage'),\n",
    "    f.when(df.days_since_last_visit >= 0, df.days_since_last_visit)\\\n",
    "                   .otherwise(-1).alias('recence_visite'),\n",
    "    f.when(df.mean_mt_voyage > 0, df.mean_mt_voyage)\\\n",
    "                   .otherwise(-1).alias('mean_mt_voyage'),\n",
    "    f.when(df.anciennete >= 0, df.anciennete)\\\n",
    "                   .otherwise(-1).alias('anciennete'),\n",
    "    f.when(df.nb_od > 0, df.nb_od)\\\n",
    "                   .otherwise(-1).alias('nb_od'),\n",
    "    f.when(df.mean_nb_passagers > 0, df.mean_nb_passagers)\\\n",
    "                   .otherwise(-1).alias('mean_nb_passagers'),\n",
    "    f.when(df.mean_tarif_loisir >= 0, df.mean_tarif_loisir)\\\n",
    "                   .otherwise(-1).alias('mean_tarif_loisir'),\n",
    "    f.when(df.mean_classe_1 >= 0, df.mean_classe_1)\\\n",
    "                   .otherwise(-1).alias('mean_classe_1'),\n",
    "    f.when(df.mean_pointe >= 0, df.mean_pointe)\\\n",
    "                   .otherwise(-1).alias('mean_pointe'),\n",
    "    f.when(df.mean_depart_we >= 0, df.mean_depart_we)\\\n",
    "                   .otherwise(-1).alias('mean_depart_we'),\n",
    "    f.when(df.tx_conversion >= 0, df.tx_conversion)\\\n",
    "                   .otherwise(-1).alias('tx_conversion'),\n",
    "    f.when(df.flg_cmd_lowcost == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_cmd_lowcost'),\n",
    "    f.when(df.flg_track_nl_lowcost == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_track_nl_lowcost'), \n",
    "    f.when(df.flg_track_nl == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_track_nl'))\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = input_df(per17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessed_df(df, label=\"flg_cmd_lowcostIndex\"):\n",
    "    max_values_to_define_str_cols = 10\n",
    "    id_col = 'ID_CLIENT'\n",
    "    \n",
    "    dty = dict(df.dtypes)\n",
    "    str_cols = [k for k, v in dty.items() if v == 'string']\n",
    "    str_cols.remove(id_col)\n",
    "    \n",
    "    for c in str_cols:\n",
    "        stringIndexer = StringIndexer(inputCol=c, outputCol=c+\"Index\")\n",
    "        model_str = stringIndexer.fit(df)\n",
    "        df = model_str.transform(df).drop(c)\n",
    "\n",
    "    input_cols = df.columns\n",
    "    input_cols.remove(id_col)\n",
    "    input_cols.remove(label)\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=input_cols,\n",
    "                            outputCol=\"features\")\n",
    "    df = assembler.transform(df)\n",
    "    \n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                   outputCol=\"indexedFeatures\", \n",
    "                   maxCategories=max_values_to_define_str_cols).fit(df)\n",
    "    return featureIndexer.transform(df), df\n",
    "\n",
    "\n",
    "data, dff = preprocessed_df(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID_CLIENT='000843db32fbaecfbb047ca0bb04b1f9f4d9425a', age=36.77269796022761, recence_cmd=36.0, mean_duree_voyage=274.6666666666667, recence_visite=8.0, mean_mt_voyage=58.666666666666664, anciennete=1550.0, nb_od=1.0, mean_nb_passagers=1.0, mean_tarif_loisir=0.0, mean_classe_1=0.0, mean_pointe=0.0, mean_depart_we=0.0, tx_conversion=0.1111111111111111, geo_trainIndex=0.0, geo_airIndex=2.0, cc_jeunesIndex=0.0, segt_rfmIndex=2.0, segt_anticipationIndex=4.0, segt_comportementalIndex=6.0, segt_nlIndex=1.0, flg_cmd_lowcostIndex=0.0, flg_track_nl_lowcostIndex=0.0, flg_track_nlIndex=0.0, features=DenseVector([36.7727, 36.0, 274.6667, 8.0, 58.6667, 1550.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1111, 0.0, 2.0, 0.0, 2.0, 4.0, 6.0, 1.0, 0.0, 0.0]), indexedFeatures=DenseVector([36.7727, 36.0, 274.6667, 8.0, 58.6667, 1550.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1111, 0.0, 2.0, 0.0, 2.0, 4.0, 6.0, 1.0, 0.0, 0.0]))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the first row of our data\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prelever un sample de data pour notre modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data.sample(False, 0.01, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10954"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelle est le label est renseigne pour la modelisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le label est \"flg_cmd_lowcostIndex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data\n",
    "train, test = sample_data.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start performing our logistic regression \n",
    "\n",
    "lr = LogisticRegression(labelCol=\"flg_cmd_lowcostIndex\", \n",
    "                        featuresCol=\"indexedFeatures\",elasticNetParam=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit the logistic model\n",
    "model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faire une fonction qui retourne score, recall, precision, AUC sous forme de dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make our function , it returns accuracy, precision, recall and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def compute_model(method,label, data) :\n",
    "    \n",
    "    skill = method \n",
    "    \n",
    "    train, test = data.randomSplit([0.8, 0.2], seed=12345)\n",
    "    \n",
    "    model = skill.fit(train)\n",
    "    \n",
    "    predict_test = model.transform(test)\n",
    "    \n",
    "    results = predict_test.select(['prediction', label])\n",
    "    \n",
    "    predictionAndLabels = results.rdd\n",
    "\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    accuracy=(cm[0][0]+cm[1][1])/cm.sum()\n",
    "\n",
    "    precision=(cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    recall=(cm[0][0])/(cm[0][0]+cm[0][1])\n",
    "    \n",
    "    \n",
    "    evaluator=BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\",\n",
    "                                            labelCol = label)\n",
    "    \n",
    "    AUC = evaluator.evaluate(predict_test)\n",
    "    \n",
    "    result = {\"score\" : accuracy, \"precision\" : precision, \"recall\" : recall, \"AUC\" : AUC}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9662769784172662,\n",
       " 'precision': 0.9641148325358851,\n",
       " 'recall': 1.0,\n",
       " 'AUC': 0.903076210716278}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_model(lr, \"flg_cmd_lowcostIndex\", sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predire alors les clients lowcoast sur un sample de data n'ayant pas servi à l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We predict on our test data\n",
    "predict_test = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|flg_cmd_lowcostIndex|prediction|\n",
      "+--------------------+----------+\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 1.0|       1.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 1.0|       1.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We print prediction and real value of \"flg_cmd_lowcostIndex\"\n",
    "predict_test.select(\"flg_cmd_lowcostIndex\",\"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(labelCol=\"flg_cmd_lowcostIndex\", \n",
    "                                    featuresCol=\"indexedFeatures\",\n",
    "                                    maxDepth=15, numTrees=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = classifier.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluer les performance de notre modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# une autre technique pour evaluer le modele\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put all in the function compute_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.966726618705036,\n",
       " 'precision': 0.964576352321685,\n",
       " 'recall': 1.0,\n",
       " 'AUC': 0.937663694539755}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_model(classifier, \"flg_cmd_lowcostIndex\", sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA FRAME PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "scoreAndLabels = map(lambda x: (Vectors.dense([1.0 - x[0], x[0]]), x[1]),\n",
    "                     [(0.1, 0.0), (0.1, 1.0), (0.4, 0.0), (0.6, 0.0), (0.6, 1.0), (0.6, 1.0), (0.8, 1.0)])\n",
    "dataset = spark_session.createDataFrame(scoreAndLabels, [\"raw\", \"label\"])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how to create a spark data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Ankit</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>Jalfaizy</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>saurabh</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>Bala</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>Jules</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>Arild</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>sarah</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>Boly</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>Anita</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>Jules</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>Soul</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>Gral</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>Apoh</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Dony</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>Tanoh</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Issouf</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Bilé</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-05-03</td>\n",
       "      <td>Gagnon</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>Papiss</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Kravitz</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Mouli</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>Jacques</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>soum</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>36</td>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>MBra</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age        date      name sex\n",
       "0    25  2018-01-03     Ankit   F\n",
       "1    22  2018-02-03  Jalfaizy   F\n",
       "2    20  2018-01-05   saurabh   F\n",
       "3    26  2018-01-12      Bala   F\n",
       "4    19  2018-07-09     Jules   F\n",
       "5    43  2018-03-18     Arild   M\n",
       "6    20  2018-01-05     sarah   M\n",
       "7    33  2018-08-12      Boly   M\n",
       "8    35  2018-04-06     Anita   M\n",
       "9    22  2018-12-06     Jules   M\n",
       "10   20  2018-07-24      Soul   F\n",
       "11   54  2018-06-17      Gral   F\n",
       "12   18  2018-09-07      Apoh   F\n",
       "13   32  2018-10-04      Dony   F\n",
       "14   31  2018-02-05     Tanoh   F\n",
       "15   27  2018-11-12    Issouf   M\n",
       "16   29  2018-10-03      Bilé   M\n",
       "17   20  2018-05-03    Gagnon   M\n",
       "18   28  2018-03-05    Papiss   M\n",
       "19   34  2018-02-12   Kravitz   M\n",
       "20   35  2018-05-09     Mouli   F\n",
       "21   27  2018-08-03   Jacques   F\n",
       "22   22  2018-12-05      soum   F\n",
       "23   36  2018-04-12      MBra   F"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "import datetime\n",
    "\n",
    "l = [(datetime.date(2018,1,3), 'Ankit',25, 'F'),\n",
    "     (datetime.date(2018,2,3), 'Jalfaizy',22,'F'),\n",
    "     (datetime.date(2018,1,5), 'saurabh',20,'F'),\n",
    "     (datetime.date(2018,1,12), 'Bala',26,'F'),\n",
    "     (datetime.date(2018,7,9), 'Jules',19,'F') ,\n",
    "     (datetime.date(2018,3,18), 'Arild',43,'M'),\n",
    "     (datetime.date(2018,1,5), 'sarah',20,'M'),\n",
    "     (datetime.date(2018,8,12), 'Boly',33,'M'),\n",
    "     (datetime.date(2018,4,6), 'Anita',35,'M'),\n",
    "     (datetime.date(2018,12,6), 'Jules',22,'M'),\n",
    "     (datetime.date(2018,7,24), 'Soul',20,'F'),\n",
    "     (datetime.date(2018,6,17), 'Gral',54,'F'),\n",
    "     (datetime.date(2018,9,7), 'Apoh',18,'F'),\n",
    "     (datetime.date(2018,10,4), 'Dony',32,'F'),\n",
    "     (datetime.date(2018,2,5), 'Tanoh',31,'F'),\n",
    "     (datetime.date(2018,11,12), 'Issouf',27,'M'),\n",
    "     (datetime.date(2018,10,3), 'Bilé',29,'M'),\n",
    "     (datetime.date(2018,5,3), 'Gagnon',20,'M'),\n",
    "     (datetime.date(2018,3,5), 'Papiss',28,'M'),\n",
    "     (datetime.date(2018,2,12), 'Kravitz',34,'M'),\n",
    "     (datetime.date(2018,5,9), 'Mouli',35,'F'),\n",
    "     (datetime.date(2018,8,3), 'Jacques',27,'F'),\n",
    "     (datetime.date(2018,12,5), 'soum',22,'F'),\n",
    "     (datetime.date(2018,4,12), 'MBra',36,'F')]\n",
    "\n",
    "rdd = spark_session.sparkContext.parallelize(l)\n",
    "people = rdd.map(lambda x: Row(date=x[0], name=x[1], age=int(x[2]), sex = x[3]))\n",
    "schemaPeople = spark_session.createDataFrame(people)\n",
    "schemaPeople.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- compter le nombre de personne totale \n",
    "2- compter le nombre de fille et de garcon\n",
    "3- quel est l'age moyen, median mini et maxi dans chaque groupe (garcon, fille)\n",
    "4 - quelle est la date de dernière visite de chaque client par rapport à la date d'aujourd'hui (la colonne date correspond à la date de visite)\n",
    "5 - quels sont les personnes qui ont une date de visite < 400 jours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_max</th>\n",
       "      <th>days_since_last_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Ankit</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>Jalfaizy</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>saurabh</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>Bala</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>Jules</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>Arild</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>sarah</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>Boly</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>Anita</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>Jules</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>Soul</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>Gral</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>Apoh</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Dony</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>Tanoh</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Issouf</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Bilé</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-05-03</td>\n",
       "      <td>Gagnon</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>Papiss</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Kravitz</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Mouli</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>Jacques</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>soum</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>36</td>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>MBra</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age        date      name sex    date_max  days_since_last_visit\n",
       "0    25  2018-01-03     Ankit   F  2019-11-02                    668\n",
       "1    22  2018-02-03  Jalfaizy   F  2019-11-02                    637\n",
       "2    20  2018-01-05   saurabh   F  2019-11-02                    666\n",
       "3    26  2018-01-12      Bala   F  2019-11-02                    659\n",
       "4    19  2018-07-09     Jules   F  2019-11-02                    481\n",
       "5    43  2018-03-18     Arild   M  2019-11-02                    594\n",
       "6    20  2018-01-05     sarah   M  2019-11-02                    666\n",
       "7    33  2018-08-12      Boly   M  2019-11-02                    447\n",
       "8    35  2018-04-06     Anita   M  2019-11-02                    575\n",
       "9    22  2018-12-06     Jules   M  2019-11-02                    331\n",
       "10   20  2018-07-24      Soul   F  2019-11-02                    466\n",
       "11   54  2018-06-17      Gral   F  2019-11-02                    503\n",
       "12   18  2018-09-07      Apoh   F  2019-11-02                    421\n",
       "13   32  2018-10-04      Dony   F  2019-11-02                    394\n",
       "14   31  2018-02-05     Tanoh   F  2019-11-02                    635\n",
       "15   27  2018-11-12    Issouf   M  2019-11-02                    355\n",
       "16   29  2018-10-03      Bilé   M  2019-11-02                    395\n",
       "17   20  2018-05-03    Gagnon   M  2019-11-02                    548\n",
       "18   28  2018-03-05    Papiss   M  2019-11-02                    607\n",
       "19   34  2018-02-12   Kravitz   M  2019-11-02                    628\n",
       "20   35  2018-05-09     Mouli   F  2019-11-02                    542\n",
       "21   27  2018-08-03   Jacques   F  2019-11-02                    456\n",
       "22   22  2018-12-05      soum   F  2019-11-02                    332\n",
       "23   36  2018-04-12      MBra   F  2019-11-02                    569"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = schemaPeople.select(\"*\",\n",
    "                         f.lit(datetime.date.today()).alias(\"date_max\"))\n",
    "dd.select(\"*\", f.datediff('date_max', 'date')\\\n",
    "                    .alias('days_since_last_visit')).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1- compter le nombre de personne totale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compter le nombre total de personnes\n",
    "schemaPeople.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- compter le nombre de fille et de garcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|   14|\n",
      "|  M|   10|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of personne by sex\n",
    "schemaPeople.groupBy(\"sex\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- quel est l'age moyen, median mini et maxi dans chaque groupe (garcon, fille)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+\n",
      "|avg(age)|min(age)|max(age)|\n",
      "+--------+--------+--------+\n",
      "|   28.25|      18|      54|\n",
      "+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, min, max\n",
    "schemaPeople.select([mean('age'), min('age'), max('age')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+---+---+-----+\n",
      "|sex|               avg|min|max|count|\n",
      "+---+------------------+---+---+-----+\n",
      "|  F|27.642857142857142| 18| 54|   14|\n",
      "|  M|              29.1| 20| 43|   10|\n",
      "+---+------------------+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.groupby('sex').agg(f.mean(schemaPeople.age).alias('avg'),\n",
    "    f.min(schemaPeople.age).alias('min'),\n",
    "    f.max(schemaPeople.age).alias('max'),\n",
    "    f.count(schemaPeople.age).alias('count')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|sex|min(age)|\n",
      "+---+--------+\n",
      "|  F|      18|\n",
      "|  M|      20|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.groupby('sex').agg({'age': 'mean', 'age': 'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|sex|          avg(age)|\n",
      "+---+------------------+\n",
      "|  F|27.642857142857142|\n",
      "|  M|              29.1|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average age by sex \n",
    "schemaPeople.groupBy('sex').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|sex|max(age)|\n",
      "+---+--------+\n",
      "|  F|      54|\n",
      "|  M|      43|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Max age by sex \n",
    "schemaPeople.groupBy('sex').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|sex|min(age)|\n",
      "+---+--------+\n",
      "|  F|      18|\n",
      "|  M|      20|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Min age by se\n",
    "schemaPeople.groupBy('sex').min().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.0, 27.0, 33.0]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First quartil , Median ,Thrid quartil  age by sex\n",
    "\n",
    "schemaPeople.approxQuantile(\"age\", [0.25,0.5, 0.75], 0.000001)\n",
    "#schemaPeople.groupBy(\"sex\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - quelle est la date de dernière visite de chaque \n",
    "#### client par rapport à la date d'aujourd'hui (la colonne date correspond à la date de visite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_max</th>\n",
       "      <th>days_since_last_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Ankit</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>Jalfaizy</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>saurabh</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>Bala</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>Jules</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>Arild</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>sarah</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>Boly</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>Anita</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>Jules</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>Soul</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>Gral</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>Apoh</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Dony</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>Tanoh</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Issouf</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Bilé</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-05-03</td>\n",
       "      <td>Gagnon</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>Papiss</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Kravitz</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Mouli</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>Jacques</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>soum</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>36</td>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>MBra</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age        date      name sex    date_max  days_since_last_visit\n",
       "0    25  2018-01-03     Ankit   F  2019-11-02                    668\n",
       "1    22  2018-02-03  Jalfaizy   F  2019-11-02                    637\n",
       "2    20  2018-01-05   saurabh   F  2019-11-02                    666\n",
       "3    26  2018-01-12      Bala   F  2019-11-02                    659\n",
       "4    19  2018-07-09     Jules   F  2019-11-02                    481\n",
       "5    43  2018-03-18     Arild   M  2019-11-02                    594\n",
       "6    20  2018-01-05     sarah   M  2019-11-02                    666\n",
       "7    33  2018-08-12      Boly   M  2019-11-02                    447\n",
       "8    35  2018-04-06     Anita   M  2019-11-02                    575\n",
       "9    22  2018-12-06     Jules   M  2019-11-02                    331\n",
       "10   20  2018-07-24      Soul   F  2019-11-02                    466\n",
       "11   54  2018-06-17      Gral   F  2019-11-02                    503\n",
       "12   18  2018-09-07      Apoh   F  2019-11-02                    421\n",
       "13   32  2018-10-04      Dony   F  2019-11-02                    394\n",
       "14   31  2018-02-05     Tanoh   F  2019-11-02                    635\n",
       "15   27  2018-11-12    Issouf   M  2019-11-02                    355\n",
       "16   29  2018-10-03      Bilé   M  2019-11-02                    395\n",
       "17   20  2018-05-03    Gagnon   M  2019-11-02                    548\n",
       "18   28  2018-03-05    Papiss   M  2019-11-02                    607\n",
       "19   34  2018-02-12   Kravitz   M  2019-11-02                    628\n",
       "20   35  2018-05-09     Mouli   F  2019-11-02                    542\n",
       "21   27  2018-08-03   Jacques   F  2019-11-02                    456\n",
       "22   22  2018-12-05      soum   F  2019-11-02                    332\n",
       "23   36  2018-04-12      MBra   F  2019-11-02                    569"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = schemaPeople.select(\"*\",\n",
    "                         f.lit(datetime.date.today()).alias(\"date_max\"))\n",
    "dd.select(\"*\", f.datediff('date_max', 'date')\\\n",
    "                    .alias('days_since_last_visit')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "jj = dd.select(\"*\", f.datediff('date_max', 'date')\\\n",
    "                    .alias('days_since_last_visit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj.filter(jj['days_since_last_visit'] < 400).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifier s'il y a des valeurs manquantes\n",
    "# Rajouter une colonne mois correspondant au mois de chaque individu dans le data frame\n",
    "# Créer une colonne adulte qui prendra la valeur 0 pour les personnes de moins de 25 ans et 1 dans le cas contraire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifier s'il y a des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  date  name  sex\n",
       "0    0     0     0    0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of missiong values\n",
    "from pyspark.sql.functions import col,sum\n",
    "# We can count the missing values by summing the boolean output of the isNull() method\n",
    "\n",
    "check_missing_values(schemaPeople)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Créer une colonne adulte qui prendra \n",
    "#### la valeur 0 pour les personnes de moins de 25 ans et 1 dans le cas contraire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une colonne adulte qui prendra \n",
    "#la valeur 0 pour les personnes de moins de 25 ans et 1 dans le cas contraire\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "schemaPeople = schemaPeople.withColumn('adulte',\n",
    "    F.when((schemaPeople.age < 25), 0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+---+------+\n",
      "|age|      date|    name|sex|adulte|\n",
      "+---+----------+--------+---+------+\n",
      "| 25|2018-01-03|   Ankit|  F|     1|\n",
      "| 22|2018-02-03|Jalfaizy|  F|     0|\n",
      "+---+----------+--------+---+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rajouter une colonne mois correspondant au mois de chaque individu dans le data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column corresponding to each month of every individual\n",
    "\n",
    "def add_column_month(df) :\n",
    "\n",
    "    df = df.withColumn('mois',\n",
    "        F.month(df.date))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>adulte</th>\n",
       "      <th>mois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Ankit</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>Jalfaizy</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        date      name sex  adulte  mois\n",
       "0   25  2018-01-03     Ankit   F       1     1\n",
       "1   22  2018-02-03  Jalfaizy   F       0     2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_column_month(schemaPeople).toPandas().iloc[0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adulte</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adulte  count\n",
       "0       1     15\n",
       "1       0      9"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemaPeople.groupby('adulte').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
      "\u001b[K     |██████▎                         | 1.4MB 1.2kB/s eta 1:17:32"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
