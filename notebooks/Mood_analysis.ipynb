{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def05956-2363-4754-bb68-a58a2aff013c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import com.google.gson.{Gson, JsonElement}\n",
       "import org.apache.hadoop.fs.{FileSystem, Path}\n",
       "import org.apache.log4j.Level\n",
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.storage.StorageLevel\n",
       "import org.slf4j.LoggerFactory\n",
       "import java.text.SimpleDateFormat\n",
       "import java.util.{Calendar, Locale}\n",
       "import scala.sys.process._\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.google.gson.{Gson, JsonElement}\n",
    "import org.apache.hadoop.fs.{FileSystem, Path}\n",
    "import org.apache.log4j.Level\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import org.slf4j.LoggerFactory\n",
    "\n",
    "import java.text.SimpleDateFormat\n",
    "import java.util.{Calendar, Locale}\n",
    "import scala.sys.process._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e869e1f9-fe64-43c8-b452-0266c58204e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------------+--------------------+------------------+----------------+--------------------+------------------+-----------------------+-------------------+-----+------------+---------------+--------------+---------------+----------------+-----------------+-----------------+-------------------+----------+----------+----------------+-------------------+--------------------+-------------------+--------------------+----------+----------+--------------------+-------------------+--------------------+------------------+--------------------+-----------------+------------------+----------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------+-----------+-------------------+--------+--------+--------------+------------+----------------+------------+--------------+------------+-------+-----------+---------------+-----------------+------------------+--------------+-------------------+---------------+--------------+------------+--------------------+----------------------+----------------+-------------------+----------+------+----------------+---------------+---------+---------------+-------------------+------------+-------------+----------------+----------------+------------------+------------------+------------------+--------------------+----------------+------------------+-------+-------+------------+----------------+---------------+--------------------+-------------------+------------------+--------+----------+--------------+---------+----------+\n",
      "|SENDER_MSISDN|    MSISDN|    RECEIVER_USER_ID|      SENDER_USER_ID|TRANSACTION_AMOUNT|COMMISSIONS_PAID|COMMISSIONS_RECEIVED|COMMISSIONS_OTHERS|SERVICE_CHARGE_RECEIVED|SERVICE_CHARGE_PAID|TAXES|SERVICE_TYPE|TRANSFER_STATUS|SENDER_PRE_BAL|SENDER_POST_BAL|RECEIVER_PRE_BAL|RECEIVER_POST_BAL|SENDER_ACC_STATUS|RECEIVER_ACC_STATUS|ERROR_CODE|ERROR_DESC|REFERENCE_NUMBER|         CREATED_ON|          CREATED_BY|        MODIFIED_ON|         MODIFIED_BY|APP_1_DATE|APP_2_DATE|         TRANSFER_ID|  TRANSFER_DATETIME|SENDER_CATEGORY_CODE|SENDER_DOMAIN_CODE|   SENDER_GRADE_NAME|SENDER_GROUP_ROLE|SENDER_DESIGNATION|    SENDER_STATE|RECEIVER_CATEGORY_CODE|RECEIVER_DOMAIN_CODE| RECEIVER_GRADE_NAME| RECEIVER_GROUP_ROLE|RECEIVER_DESIGNATION|RECEIVER_STATE|SENDER_CITY|      RECEIVER_CITY|APP_1_BY|APP_2_BY|REQUEST_SOURCE|GATEWAY_TYPE|TRANSFER_SUBTYPE|PAYMENT_TYPE|PAYMENT_NUMBER|PAYMENT_DATE|REMARKS|ACTION_TYPE|TRANSACTION_TAG|RECONCILIATION_BY|RECONCILIATION_FOR|EXT_TXN_NUMBER|ORIGINAL_REF_NUMBER|ZEBRA_AMBIGUOUS|ATTEMPT_STATUS|OTHER_MSISDN|SENDER_WALLET_NUMBER|RECEIVER_WALLET_NUMBER|SENDER_USER_NAME| RECEIVER_USER_NAME|TNO_MSISDN|TNO_ID|UNREG_FIRST_NAME|UNREG_LAST_NAME|UNREG_DOB|UNREG_ID_NUMBER|BULK_PAYOUT_BATCHID|IS_FINANCIAL|TRANSFER_DONE|INITIATOR_MSISDN|VALIDATOR_MSISDN|INITIATOR_COMMENTS|VALIDATOR_COMMENTS|SENDER_WALLET_NAME|RECIEVER_WALLET_NAME|SENDER_USER_TYPE|RECEIVER_USER_TYPE|TXNMODE|    TAG|OWNER_MSISDN|USER_DOMAIN_CODE|USER_GRADE_NAME|             USER_ID|          WEB_LOGIN|USER_CATEGORY_CODE|ADDRESS2|GROUP_ROLE|PARTENAIRE_NEW|  ACTEURS|     TYPE2|\n",
      "+-------------+----------+--------------------+--------------------+------------------+----------------+--------------------+------------------+-----------------------+-------------------+-----+------------+---------------+--------------+---------------+----------------+-----------------+-----------------+-------------------+----------+----------+----------------+-------------------+--------------------+-------------------+--------------------+----------+----------+--------------------+-------------------+--------------------+------------------+--------------------+-----------------+------------------+----------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------+-----------+-------------------+--------+--------+--------------+------------+----------------+------------+--------------+------------+-------+-----------+---------------+-----------------+------------------+--------------+-------------------+---------------+--------------+------------+--------------------+----------------------+----------------+-------------------+----------+------+----------------+---------------+---------+---------------+-------------------+------------+-------------+----------------+----------------+------------------+------------------+------------------+--------------------+----------------+------------------+-------+-------+------------+----------------+---------------+--------------------+-------------------+------------------+--------+----------+--------------+---------+----------+\n",
      "|   0788458782|0787912822|PT201009.1735.019444|PT161018.1230.269121|            5000.0|             0.0|                 0.0|               0.0|                   50.0|                0.0|  0.0|     CASHOUT|             TS|      102596.0|        97546.0|         24237.0|          29237.0|                Y|                  Y|      null|      null|            null|02/02/2023 00:03:27|PT201009.1735.019444|02/02/2023 00:03:54|PT161018.1230.269121|      null|      null|CO230202.0003.A78976|02/02/2023 00:03:54|                SUBS|              SUBS|Subscriber Lite B...|             null|              null|REJET 20/01/2017|               PDVTYP2|            GRSTYPE2|PDV Type 2 Indepe...|BA201009.1735.019441|               DIST2|       ABIDJAN|     SINFRA|BESSOU DEKAME SONIA|    null|    null|       BROWSER|        USSD|         CASHOUT|        null|          null|        null|   null|   CREATION|        CASHOUT|             null|              null|          null|               null|           null|          null|        null|     101120007505406|       101120016422172|  KOUASSI NAZERE|IND SONICONNEX3 PDV|      null|  null|            null|           null|     null|           null|               null|           Y|            Y|            null|            null|              null|              null|            Normal|              Normal|      SUBSCRIBER|           CHANNEL|   null|CASHOUT|        null|            null|           null|                null|               null|              null|    null|      null|          null|     null|      null|\n",
      "|   0749003014|0757715267|PT120217.1858.000001|PT120810.1426.000002|            5000.0|             0.0|                 0.0|               0.0|                   50.0|                0.0|  0.0|     CASHOUT|             TS|        5865.5|          815.5|       2941100.0|        2946100.0|                Y|                  Y|      null|      null|            null|02/02/2023 00:04:30|PT120217.1858.000001|02/02/2023 00:05:27|PT120810.1426.000002|      null|      null|CO230202.0004.C28533|02/02/2023 00:05:27|                SUBS|              SUBS|   Normal Subscriber|             null|              null|            null|               PDVTYP1|            GRSTYPE1|     Grossiste 1 PDV|            MPAYDC18|                null|          null|    TOUMODI|               null|    null|    null|       BROWSER|        USSD|         CASHOUT|        null|          null|        null|   null|   CREATION|        CASHOUT|             null|              null|          null|               null|           null|          null|        null|    1208101426000002|      1202171858000001|     konan david|AJS_sodeciyakro_cc2|      null|  null|            null|           null|     null|           null|               null|           Y|            Y|            null|            null|              null|              null|            Normal|              Normal|      SUBSCRIBER|           CHANNEL|   null|CASHOUT|  0708475526|        GRSTYPE1|Grossiste 1 PDV|PT120217.1858.000001|AJS_sodeciyakro_cc2|           PDVTYP1|    null|  MPAYDC18|           AJS|FRANCHISE|PARTENAIRE|\n",
      "+-------------+----------+--------------------+--------------------+------------------+----------------+--------------------+------------------+-----------------------+-------------------+-----+------------+---------------+--------------+---------------+----------------+-----------------+-----------------+-------------------+----------+----------+----------------+-------------------+--------------------+-------------------+--------------------+----------+----------+--------------------+-------------------+--------------------+------------------+--------------------+-----------------+------------------+----------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------+-----------+-------------------+--------+--------+--------------+------------+----------------+------------+--------------+------------+-------+-----------+---------------+-----------------+------------------+--------------+-------------------+---------------+--------------+------------+--------------------+----------------------+----------------+-------------------+----------+------+----------------+---------------+---------+---------------+-------------------+------------+-------------+----------------+----------------+------------------+------------------+------------------+--------------------+----------------+------------------+-------+-------+------------+----------------+---------------+--------------------+-------------------+------------------+--------+----------+--------------+---------+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- SENDER_MSISDN: string (nullable = true)\n",
      " |-- MSISDN: string (nullable = true)\n",
      " |-- RECEIVER_USER_ID: string (nullable = true)\n",
      " |-- SENDER_USER_ID: string (nullable = true)\n",
      " |-- TRANSACTION_AMOUNT: string (nullable = true)\n",
      " |-- COMMISSIONS_PAID: string (nullable = true)\n",
      " |-- COMMISSIONS_RECEIVED: string (nullable = true)\n",
      " |-- COMMISSIONS_OTHERS: string (nullable = true)\n",
      " |-- SERVICE_CHARGE_RECEIVED: string (nullable = true)\n",
      " |-- SERVICE_CHARGE_PAID: string (nullable = true)\n",
      " |-- TAXES: string (nullable = true)\n",
      " |-- SERVICE_TYPE: string (nullable = true)\n",
      " |-- TRANSFER_STATUS: string (nullable = true)\n",
      " |-- SENDER_PRE_BAL: string (nullable = true)\n",
      " |-- SENDER_POST_BAL: string (nullable = true)\n",
      " |-- RECEIVER_PRE_BAL: string (nullable = true)\n",
      " |-- RECEIVER_POST_BAL: string (nullable = true)\n",
      " |-- SENDER_ACC_STATUS: string (nullable = true)\n",
      " |-- RECEIVER_ACC_STATUS: string (nullable = true)\n",
      " |-- ERROR_CODE: string (nullable = true)\n",
      " |-- ERROR_DESC: string (nullable = true)\n",
      " |-- REFERENCE_NUMBER: string (nullable = true)\n",
      " |-- CREATED_ON: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- MODIFIED_ON: string (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- APP_1_DATE: string (nullable = true)\n",
      " |-- APP_2_DATE: string (nullable = true)\n",
      " |-- TRANSFER_ID: string (nullable = true)\n",
      " |-- TRANSFER_DATETIME: string (nullable = true)\n",
      " |-- SENDER_CATEGORY_CODE: string (nullable = true)\n",
      " |-- SENDER_DOMAIN_CODE: string (nullable = true)\n",
      " |-- SENDER_GRADE_NAME: string (nullable = true)\n",
      " |-- SENDER_GROUP_ROLE: string (nullable = true)\n",
      " |-- SENDER_DESIGNATION: string (nullable = true)\n",
      " |-- SENDER_STATE: string (nullable = true)\n",
      " |-- RECEIVER_CATEGORY_CODE: string (nullable = true)\n",
      " |-- RECEIVER_DOMAIN_CODE: string (nullable = true)\n",
      " |-- RECEIVER_GRADE_NAME: string (nullable = true)\n",
      " |-- RECEIVER_GROUP_ROLE: string (nullable = true)\n",
      " |-- RECEIVER_DESIGNATION: string (nullable = true)\n",
      " |-- RECEIVER_STATE: string (nullable = true)\n",
      " |-- SENDER_CITY: string (nullable = true)\n",
      " |-- RECEIVER_CITY: string (nullable = true)\n",
      " |-- APP_1_BY: string (nullable = true)\n",
      " |-- APP_2_BY: string (nullable = true)\n",
      " |-- REQUEST_SOURCE: string (nullable = true)\n",
      " |-- GATEWAY_TYPE: string (nullable = true)\n",
      " |-- TRANSFER_SUBTYPE: string (nullable = true)\n",
      " |-- PAYMENT_TYPE: string (nullable = true)\n",
      " |-- PAYMENT_NUMBER: string (nullable = true)\n",
      " |-- PAYMENT_DATE: string (nullable = true)\n",
      " |-- REMARKS: string (nullable = true)\n",
      " |-- ACTION_TYPE: string (nullable = true)\n",
      " |-- TRANSACTION_TAG: string (nullable = true)\n",
      " |-- RECONCILIATION_BY: string (nullable = true)\n",
      " |-- RECONCILIATION_FOR: string (nullable = true)\n",
      " |-- EXT_TXN_NUMBER: string (nullable = true)\n",
      " |-- ORIGINAL_REF_NUMBER: string (nullable = true)\n",
      " |-- ZEBRA_AMBIGUOUS: string (nullable = true)\n",
      " |-- ATTEMPT_STATUS: string (nullable = true)\n",
      " |-- OTHER_MSISDN: string (nullable = true)\n",
      " |-- SENDER_WALLET_NUMBER: string (nullable = true)\n",
      " |-- RECEIVER_WALLET_NUMBER: string (nullable = true)\n",
      " |-- SENDER_USER_NAME: string (nullable = true)\n",
      " |-- RECEIVER_USER_NAME: string (nullable = true)\n",
      " |-- TNO_MSISDN: string (nullable = true)\n",
      " |-- TNO_ID: string (nullable = true)\n",
      " |-- UNREG_FIRST_NAME: string (nullable = true)\n",
      " |-- UNREG_LAST_NAME: string (nullable = true)\n",
      " |-- UNREG_DOB: string (nullable = true)\n",
      " |-- UNREG_ID_NUMBER: string (nullable = true)\n",
      " |-- BULK_PAYOUT_BATCHID: string (nullable = true)\n",
      " |-- IS_FINANCIAL: string (nullable = true)\n",
      " |-- TRANSFER_DONE: string (nullable = true)\n",
      " |-- INITIATOR_MSISDN: string (nullable = true)\n",
      " |-- VALIDATOR_MSISDN: string (nullable = true)\n",
      " |-- INITIATOR_COMMENTS: string (nullable = true)\n",
      " |-- VALIDATOR_COMMENTS: string (nullable = true)\n",
      " |-- SENDER_WALLET_NAME: string (nullable = true)\n",
      " |-- RECIEVER_WALLET_NAME: string (nullable = true)\n",
      " |-- SENDER_USER_TYPE: string (nullable = true)\n",
      " |-- RECEIVER_USER_TYPE: string (nullable = true)\n",
      " |-- TXNMODE: string (nullable = true)\n",
      " |-- TAG: string (nullable = true)\n",
      " |-- OWNER_MSISDN: string (nullable = true)\n",
      " |-- USER_DOMAIN_CODE: string (nullable = true)\n",
      " |-- USER_GRADE_NAME: string (nullable = true)\n",
      " |-- USER_ID: string (nullable = true)\n",
      " |-- WEB_LOGIN: string (nullable = true)\n",
      " |-- USER_CATEGORY_CODE: string (nullable = true)\n",
      " |-- ADDRESS2: string (nullable = true)\n",
      " |-- GROUP_ROLE: string (nullable = true)\n",
      " |-- PARTENAIRE_NEW: string (nullable = true)\n",
      " |-- ACTEURS: string (nullable = true)\n",
      " |-- TYPE2: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df_transaction_gr: org.apache.spark.sql.DataFrame = [SENDER_MSISDN: string, MSISDN: string ... 94 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df_transaction_gr = spark.read\n",
    "                        .option(\"header\", \"true\")\n",
    "                        .option(\"delimiter\", \";\")\n",
    "                        .csv(\"/Users/diakite/Downloads/Telegram Desktop/df_transaction_gr_cashout_cashin_20230202.csv\")\n",
    "\n",
    "df_transaction_gr.show(2)\n",
    "df_transaction_gr.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e643bc9-b494-400e-8e02-ed326393629a",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.SparkException",
     "evalue": " Job aborted due to stage failure: Task 0 in stage 18.0 failed 1 times, most recent failure: Lost task 0.0 in stage 18.0 (TID 18) (frabo-db-1.dev01.smile.lan executor driver): org.apache.spark.repl.RemoteClassLoaderError: org.apache.spark.sql.catalyst.expressions.Object",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 18.0 failed 1 times, most recent failure: Lost task 0.0 in stage 18.0 (TID 18) (frabo-db-1.dev01.smile.lan executor driver): org.apache.spark.repl.RemoteClassLoaderError: org.apache.spark.sql.catalyst.expressions.Object",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:120)",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:576)",
      "\tat org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40)",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
      "\tat java.base/java.lang.Class.forName0(Native Method)",
      "\tat java.base/java.lang.Class.forName(Class.java:398)",
      "\tat org.codehaus.janino.ClassLoaderIClassLoader.findIClass(ClassLoaderIClassLoader.java:89)",
      "\tat org.codehaus.janino.IClassLoader.loadIClass(IClassLoader.java:317)",
      "\tat org.codehaus.janino.UnitCompiler.findTypeByName(UnitCompiler.java:8618)",
      "\tat org.codehaus.janino.UnitCompiler.getReferenceType(UnitCompiler.java:6771)",
      "\tat org.codehaus.janino.UnitCompiler.getReferenceType(UnitCompiler.java:6620)",
      "\tat org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:6599)",
      "\tat org.codehaus.janino.UnitCompiler.access$14300(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$22$1.visitReferenceType(UnitCompiler.java:6502)",
      "\tat org.codehaus.janino.UnitCompiler$22$1.visitReferenceType(UnitCompiler.java:6497)",
      "\tat org.codehaus.janino.Java$ReferenceType.accept(Java.java:4134)",
      "\tat org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6497)",
      "\tat org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6490)",
      "\tat org.codehaus.janino.Java$ReferenceType.accept(Java.java:4133)",
      "\tat org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6490)",
      "\tat org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:6895)",
      "\tat org.codehaus.janino.UnitCompiler.access$14100(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$22$1.visitArrayType(UnitCompiler.java:6500)",
      "\tat org.codehaus.janino.UnitCompiler$22$1.visitArrayType(UnitCompiler.java:6497)",
      "\tat org.codehaus.janino.Java$ArrayType.accept(Java.java:4215)",
      "\tat org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6497)",
      "\tat org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6490)",
      "\tat org.codehaus.janino.Java$ArrayType.accept(Java.java:4214)",
      "\tat org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6490)",
      "\tat org.codehaus.janino.UnitCompiler.access$1300(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$36.getParameterTypes2(UnitCompiler.java:10451)",
      "\tat org.codehaus.janino.IClass$IInvocable.getParameterTypes(IClass.java:959)",
      "\tat org.codehaus.janino.IClass$IMethod.getDescriptor2(IClass.java:1224)",
      "\tat org.codehaus.janino.IClass$IInvocable.getDescriptor(IClass.java:982)",
      "\tat org.codehaus.janino.IClass.getIMethods(IClass.java:248)",
      "\tat org.codehaus.janino.IClass.getIMethods(IClass.java:237)",
      "\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:470)",
      "\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:410)",
      "\tat org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:389)",
      "\tat org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:384)",
      "\tat org.codehaus.janino.Java$PackageMemberClassDeclaration.accept(Java.java:1594)",
      "\tat org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:384)",
      "\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:362)",
      "\tat org.codehaus.janino.UnitCompiler.access$000(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$1.visitCompilationUnit(UnitCompiler.java:336)",
      "\tat org.codehaus.janino.UnitCompiler$1.visitCompilationUnit(UnitCompiler.java:333)",
      "\tat org.codehaus.janino.Java$CompilationUnit.accept(Java.java:363)",
      "\tat org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:333)",
      "\tat org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:235)",
      "\tat org.codehaus.janino.SimpleCompiler.compileToClassLoader(SimpleCompiler.java:464)",
      "\tat org.codehaus.janino.ClassBodyEvaluator.compileToClass(ClassBodyEvaluator.java:314)",
      "\tat org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:237)",
      "\tat org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:205)",
      "\tat org.codehaus.commons.compiler.Cookable.cook(Cookable.java:80)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:1489)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1586)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1583)",
      "\tat org.sparkproject.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)",
      "\tat org.sparkproject.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)",
      "\tat org.sparkproject.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)",
      "\tat org.sparkproject.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)",
      "\tat org.sparkproject.guava.cache.LocalCache.get(LocalCache.java:4000)",
      "\tat org.sparkproject.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)",
      "\tat org.sparkproject.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:1436)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:378)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:331)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:34)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1362)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1359)",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.appendPartitionColumns$lzycompute(FileFormat.scala:138)",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.appendPartitionColumns(FileFormat.scala:137)",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:142)",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:133)",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:187)",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:104)",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)",
      "Caused by: java.io.IOException: Failed to connect to frabo-db-1.dev01.smile.lan/192.168.1.195:55172",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:399)",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$openChannel$4(NettyRpcEnv.scala:367)",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:366)",
      "\tat org.apache.spark.repl.ExecutorClassLoader.getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:135)",
      "\tat org.apache.spark.repl.ExecutorClassLoader.$anonfun$fetchFn$1(ExecutorClassLoader.scala:66)",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:176)",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:113)",
      "\t... 96 more",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: frabo-db-1.dev01.smile.lan/192.168.1.195:55172",
      "Caused by: java.net.ConnectException: Operation timed out",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:707)",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)",
      "",
      "Driver stacktrace:",
      "  at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)",
      "  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)",
      "  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)",
      "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)",
      "  at scala.Option.foreach(Option.scala:407)",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:476)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:429)",
      "  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)",
      "  at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)",
      "  at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)",
      "  at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)",
      "  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)",
      "  at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)",
      "  at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)",
      "  at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)",
      "  at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:806)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:765)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:774)",
      "  ... 46 elided",
      "Caused by: org.apache.spark.repl.RemoteClassLoaderError: org.apache.spark.sql.catalyst.expressions.Object",
      "  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:120)",
      "  at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)",
      "  at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:576)",
      "  at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40)",
      "  at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
      "  at java.base/java.lang.Class.forName0(Native Method)",
      "  at java.base/java.lang.Class.forName(Class.java:398)",
      "  at org.codehaus.janino.ClassLoaderIClassLoader.findIClass(ClassLoaderIClassLoader.java:89)",
      "  at org.codehaus.janino.IClassLoader.loadIClass(IClassLoader.java:317)",
      "  at org.codehaus.janino.UnitCompiler.findTypeByName(UnitCompiler.java:8618)",
      "  at org.codehaus.janino.UnitCompiler.getReferenceType(UnitCompiler.java:6771)",
      "  at org.codehaus.janino.UnitCompiler.getReferenceType(UnitCompiler.java:6620)",
      "  at org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:6599)",
      "  at org.codehaus.janino.UnitCompiler.access$14300(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$22$1.visitReferenceType(UnitCompiler.java:6502)",
      "  at org.codehaus.janino.UnitCompiler$22$1.visitReferenceType(UnitCompiler.java:6497)",
      "  at org.codehaus.janino.Java$ReferenceType.accept(Java.java:4134)",
      "  at org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6497)",
      "  at org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6490)",
      "  at org.codehaus.janino.Java$ReferenceType.accept(Java.java:4133)",
      "  at org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6490)",
      "  at org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:6895)",
      "  at org.codehaus.janino.UnitCompiler.access$14100(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$22$1.visitArrayType(UnitCompiler.java:6500)",
      "  at org.codehaus.janino.UnitCompiler$22$1.visitArrayType(UnitCompiler.java:6497)",
      "  at org.codehaus.janino.Java$ArrayType.accept(Java.java:4215)",
      "  at org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6497)",
      "  at org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6490)",
      "  at org.codehaus.janino.Java$ArrayType.accept(Java.java:4214)",
      "  at org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6490)",
      "  at org.codehaus.janino.UnitCompiler.access$1300(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$36.getParameterTypes2(UnitCompiler.java:10451)",
      "  at org.codehaus.janino.IClass$IInvocable.getParameterTypes(IClass.java:959)",
      "  at org.codehaus.janino.IClass$IMethod.getDescriptor2(IClass.java:1224)",
      "  at org.codehaus.janino.IClass$IInvocable.getDescriptor(IClass.java:982)",
      "  at org.codehaus.janino.IClass.getIMethods(IClass.java:248)",
      "  at org.codehaus.janino.IClass.getIMethods(IClass.java:237)",
      "  at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:470)",
      "  at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:410)",
      "  at org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:389)",
      "  at org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:384)",
      "  at org.codehaus.janino.Java$PackageMemberClassDeclaration.accept(Java.java:1594)",
      "  at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:384)",
      "  at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:362)",
      "  at org.codehaus.janino.UnitCompiler.access$000(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$1.visitCompilationUnit(UnitCompiler.java:336)",
      "  at org.codehaus.janino.UnitCompiler$1.visitCompilationUnit(UnitCompiler.java:333)",
      "  at org.codehaus.janino.Java$CompilationUnit.accept(Java.java:363)",
      "  at org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:333)",
      "  at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:235)",
      "  at org.codehaus.janino.SimpleCompiler.compileToClassLoader(SimpleCompiler.java:464)",
      "  at org.codehaus.janino.ClassBodyEvaluator.compileToClass(ClassBodyEvaluator.java:314)",
      "  at org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:237)",
      "  at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:205)",
      "  at org.codehaus.commons.compiler.Cookable.cook(Cookable.java:80)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:1489)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1586)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1583)",
      "  at org.sparkproject.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)",
      "  at org.sparkproject.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)",
      "  at org.sparkproject.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)",
      "  at org.sparkproject.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)",
      "  at org.sparkproject.guava.cache.LocalCache.get(LocalCache.java:4000)",
      "  at org.sparkproject.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)",
      "  at org.sparkproject.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:1436)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:378)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:331)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:34)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1362)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1359)",
      "  at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.appendPartitionColumns$lzycompute(FileFormat.scala:138)",
      "  at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.appendPartitionColumns(FileFormat.scala:137)",
      "  at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:142)",
      "  at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:133)",
      "  at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)",
      "  at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:187)",
      "  at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:104)",
      "  at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)",
      "  at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)",
      "  at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
      "  at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)",
      "  at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)",
      "  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)",
      "  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)",
      "  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
      "  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)",
      "  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)",
      "  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)",
      "  at org.apache.spark.scheduler.Task.run(Task.scala:131)",
      "  at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)",
      "  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)",
      "  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)",
      "  at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)",
      "  at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)",
      "  ... 1 more",
      "Caused by: java.io.IOException: Failed to connect to frabo-db-1.dev01.smile.lan/192.168.1.195:55172",
      "  at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)",
      "  at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)",
      "  at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)",
      "  at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:399)",
      "  at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$openChannel$4(NettyRpcEnv.scala:367)",
      "  at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
      "  at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)",
      "  at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:366)",
      "  at org.apache.spark.repl.ExecutorClassLoader.getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:135)",
      "  at org.apache.spark.repl.ExecutorClassLoader.$anonfun$fetchFn$1(ExecutorClassLoader.scala:66)",
      "  at org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:176)",
      "  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:113)",
      "  ... 96 more",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: frabo-db-1.dev01.smile.lan/192.168.1.195:55172",
      "Caused by: java.net.ConnectException: Operation timed out",
      "  at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)",
      "  at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)",
      "  at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)",
      "  at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)",
      "  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:707)",
      "  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)",
      "  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)",
      "  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)",
      "  at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)",
      "  at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)",
      "  at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)",
      "  at java.base/java.lang.Thread.run(Thread.java:829)",
      ""
     ]
    }
   ],
   "source": [
    "df_transaction_gr.filter(col(\"TRANSFER_ID\").isin(\"CI230202.0019.A66740\")).select(\"MSISDN\", \"OWNER_MSISDN\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "960c44f1-6fa8-4d73-93be-608c822d5745",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.SparkException",
     "evalue": " Job aborted due to stage failure: Task 0 in stage 17.0 failed 1 times, most recent failure: Lost task 0.0 in stage 17.0 (TID 17) (frabo-db-1.dev01.smile.lan executor driver): org.apache.spark.repl.RemoteClassLoaderError: org.apache.spark.sql.catalyst.expressions.Object",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 17.0 failed 1 times, most recent failure: Lost task 0.0 in stage 17.0 (TID 17) (frabo-db-1.dev01.smile.lan executor driver): org.apache.spark.repl.RemoteClassLoaderError: org.apache.spark.sql.catalyst.expressions.Object",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:120)",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:576)",
      "\tat org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40)",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
      "\tat java.base/java.lang.Class.forName0(Native Method)",
      "\tat java.base/java.lang.Class.forName(Class.java:398)",
      "\tat org.codehaus.janino.ClassLoaderIClassLoader.findIClass(ClassLoaderIClassLoader.java:89)",
      "\tat org.codehaus.janino.IClassLoader.loadIClass(IClassLoader.java:317)",
      "\tat org.codehaus.janino.UnitCompiler.findTypeByName(UnitCompiler.java:8618)",
      "\tat org.codehaus.janino.UnitCompiler.getReferenceType(UnitCompiler.java:6771)",
      "\tat org.codehaus.janino.UnitCompiler.getReferenceType(UnitCompiler.java:6620)",
      "\tat org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:6599)",
      "\tat org.codehaus.janino.UnitCompiler.access$14300(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$22$1.visitReferenceType(UnitCompiler.java:6502)",
      "\tat org.codehaus.janino.UnitCompiler$22$1.visitReferenceType(UnitCompiler.java:6497)",
      "\tat org.codehaus.janino.Java$ReferenceType.accept(Java.java:4134)",
      "\tat org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6497)",
      "\tat org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6490)",
      "\tat org.codehaus.janino.Java$ReferenceType.accept(Java.java:4133)",
      "\tat org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6490)",
      "\tat org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:6895)",
      "\tat org.codehaus.janino.UnitCompiler.access$14100(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$22$1.visitArrayType(UnitCompiler.java:6500)",
      "\tat org.codehaus.janino.UnitCompiler$22$1.visitArrayType(UnitCompiler.java:6497)",
      "\tat org.codehaus.janino.Java$ArrayType.accept(Java.java:4215)",
      "\tat org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6497)",
      "\tat org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6490)",
      "\tat org.codehaus.janino.Java$ArrayType.accept(Java.java:4214)",
      "\tat org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6490)",
      "\tat org.codehaus.janino.UnitCompiler.access$1300(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$36.getParameterTypes2(UnitCompiler.java:10451)",
      "\tat org.codehaus.janino.IClass$IInvocable.getParameterTypes(IClass.java:959)",
      "\tat org.codehaus.janino.IClass$IMethod.getDescriptor2(IClass.java:1224)",
      "\tat org.codehaus.janino.IClass$IInvocable.getDescriptor(IClass.java:982)",
      "\tat org.codehaus.janino.IClass.getIMethods(IClass.java:248)",
      "\tat org.codehaus.janino.IClass.getIMethods(IClass.java:237)",
      "\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:470)",
      "\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:410)",
      "\tat org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:389)",
      "\tat org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:384)",
      "\tat org.codehaus.janino.Java$PackageMemberClassDeclaration.accept(Java.java:1594)",
      "\tat org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:384)",
      "\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:362)",
      "\tat org.codehaus.janino.UnitCompiler.access$000(UnitCompiler.java:226)",
      "\tat org.codehaus.janino.UnitCompiler$1.visitCompilationUnit(UnitCompiler.java:336)",
      "\tat org.codehaus.janino.UnitCompiler$1.visitCompilationUnit(UnitCompiler.java:333)",
      "\tat org.codehaus.janino.Java$CompilationUnit.accept(Java.java:363)",
      "\tat org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:333)",
      "\tat org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:235)",
      "\tat org.codehaus.janino.SimpleCompiler.compileToClassLoader(SimpleCompiler.java:464)",
      "\tat org.codehaus.janino.ClassBodyEvaluator.compileToClass(ClassBodyEvaluator.java:314)",
      "\tat org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:237)",
      "\tat org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:205)",
      "\tat org.codehaus.commons.compiler.Cookable.cook(Cookable.java:80)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:1489)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1586)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1583)",
      "\tat org.sparkproject.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)",
      "\tat org.sparkproject.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)",
      "\tat org.sparkproject.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)",
      "\tat org.sparkproject.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)",
      "\tat org.sparkproject.guava.cache.LocalCache.get(LocalCache.java:4000)",
      "\tat org.sparkproject.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)",
      "\tat org.sparkproject.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:1436)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:378)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:331)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:34)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1362)",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1359)",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.appendPartitionColumns$lzycompute(FileFormat.scala:138)",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.appendPartitionColumns(FileFormat.scala:137)",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:142)",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:133)",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:187)",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:104)",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)",
      "Caused by: java.io.IOException: Failed to connect to frabo-db-1.dev01.smile.lan/192.168.1.195:55172",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:399)",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$openChannel$4(NettyRpcEnv.scala:367)",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:366)",
      "\tat org.apache.spark.repl.ExecutorClassLoader.getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:135)",
      "\tat org.apache.spark.repl.ExecutorClassLoader.$anonfun$fetchFn$1(ExecutorClassLoader.scala:66)",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:176)",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:113)",
      "\t... 93 more",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: frabo-db-1.dev01.smile.lan/192.168.1.195:55172",
      "Caused by: java.net.ConnectException: Operation timed out",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:707)",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)",
      "",
      "Driver stacktrace:",
      "  at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)",
      "  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)",
      "  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)",
      "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)",
      "  at scala.Option.foreach(Option.scala:407)",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:476)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:429)",
      "  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)",
      "  at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)",
      "  at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)",
      "  at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)",
      "  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)",
      "  at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)",
      "  at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)",
      "  at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)",
      "  at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:806)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:765)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:774)",
      "  ... 46 elided",
      "Caused by: org.apache.spark.repl.RemoteClassLoaderError: org.apache.spark.sql.catalyst.expressions.Object",
      "  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:120)",
      "  at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)",
      "  at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:576)",
      "  at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40)",
      "  at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
      "  at java.base/java.lang.Class.forName0(Native Method)",
      "  at java.base/java.lang.Class.forName(Class.java:398)",
      "  at org.codehaus.janino.ClassLoaderIClassLoader.findIClass(ClassLoaderIClassLoader.java:89)",
      "  at org.codehaus.janino.IClassLoader.loadIClass(IClassLoader.java:317)",
      "  at org.codehaus.janino.UnitCompiler.findTypeByName(UnitCompiler.java:8618)",
      "  at org.codehaus.janino.UnitCompiler.getReferenceType(UnitCompiler.java:6771)",
      "  at org.codehaus.janino.UnitCompiler.getReferenceType(UnitCompiler.java:6620)",
      "  at org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:6599)",
      "  at org.codehaus.janino.UnitCompiler.access$14300(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$22$1.visitReferenceType(UnitCompiler.java:6502)",
      "  at org.codehaus.janino.UnitCompiler$22$1.visitReferenceType(UnitCompiler.java:6497)",
      "  at org.codehaus.janino.Java$ReferenceType.accept(Java.java:4134)",
      "  at org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6497)",
      "  at org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6490)",
      "  at org.codehaus.janino.Java$ReferenceType.accept(Java.java:4133)",
      "  at org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6490)",
      "  at org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:6895)",
      "  at org.codehaus.janino.UnitCompiler.access$14100(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$22$1.visitArrayType(UnitCompiler.java:6500)",
      "  at org.codehaus.janino.UnitCompiler$22$1.visitArrayType(UnitCompiler.java:6497)",
      "  at org.codehaus.janino.Java$ArrayType.accept(Java.java:4215)",
      "  at org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6497)",
      "  at org.codehaus.janino.UnitCompiler$22.visitType(UnitCompiler.java:6490)",
      "  at org.codehaus.janino.Java$ArrayType.accept(Java.java:4214)",
      "  at org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6490)",
      "  at org.codehaus.janino.UnitCompiler.access$1300(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$36.getParameterTypes2(UnitCompiler.java:10451)",
      "  at org.codehaus.janino.IClass$IInvocable.getParameterTypes(IClass.java:959)",
      "  at org.codehaus.janino.IClass$IMethod.getDescriptor2(IClass.java:1224)",
      "  at org.codehaus.janino.IClass$IInvocable.getDescriptor(IClass.java:982)",
      "  at org.codehaus.janino.IClass.getIMethods(IClass.java:248)",
      "  at org.codehaus.janino.IClass.getIMethods(IClass.java:237)",
      "  at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:470)",
      "  at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:410)",
      "  at org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:389)",
      "  at org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:384)",
      "  at org.codehaus.janino.Java$PackageMemberClassDeclaration.accept(Java.java:1594)",
      "  at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:384)",
      "  at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:362)",
      "  at org.codehaus.janino.UnitCompiler.access$000(UnitCompiler.java:226)",
      "  at org.codehaus.janino.UnitCompiler$1.visitCompilationUnit(UnitCompiler.java:336)",
      "  at org.codehaus.janino.UnitCompiler$1.visitCompilationUnit(UnitCompiler.java:333)",
      "  at org.codehaus.janino.Java$CompilationUnit.accept(Java.java:363)",
      "  at org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:333)",
      "  at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:235)",
      "  at org.codehaus.janino.SimpleCompiler.compileToClassLoader(SimpleCompiler.java:464)",
      "  at org.codehaus.janino.ClassBodyEvaluator.compileToClass(ClassBodyEvaluator.java:314)",
      "  at org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:237)",
      "  at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:205)",
      "  at org.codehaus.commons.compiler.Cookable.cook(Cookable.java:80)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:1489)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1586)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1583)",
      "  at org.sparkproject.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)",
      "  at org.sparkproject.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)",
      "  at org.sparkproject.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)",
      "  at org.sparkproject.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)",
      "  at org.sparkproject.guava.cache.LocalCache.get(LocalCache.java:4000)",
      "  at org.sparkproject.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)",
      "  at org.sparkproject.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:1436)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:378)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:331)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:34)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1362)",
      "  at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1359)",
      "  at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.appendPartitionColumns$lzycompute(FileFormat.scala:138)",
      "  at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.appendPartitionColumns(FileFormat.scala:137)",
      "  at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:142)",
      "  at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:133)",
      "  at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)",
      "  at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:187)",
      "  at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:104)",
      "  at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)",
      "  at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)",
      "  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)",
      "  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)",
      "  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
      "  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)",
      "  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)",
      "  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)",
      "  at org.apache.spark.scheduler.Task.run(Task.scala:131)",
      "  at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)",
      "  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)",
      "  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)",
      "  at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)",
      "  at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)",
      "  ... 1 more",
      "Caused by: java.io.IOException: Failed to connect to frabo-db-1.dev01.smile.lan/192.168.1.195:55172",
      "  at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)",
      "  at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)",
      "  at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)",
      "  at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:399)",
      "  at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$openChannel$4(NettyRpcEnv.scala:367)",
      "  at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
      "  at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)",
      "  at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:366)",
      "  at org.apache.spark.repl.ExecutorClassLoader.getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:135)",
      "  at org.apache.spark.repl.ExecutorClassLoader.$anonfun$fetchFn$1(ExecutorClassLoader.scala:66)",
      "  at org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:176)",
      "  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:113)",
      "  ... 93 more",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: frabo-db-1.dev01.smile.lan/192.168.1.195:55172",
      "Caused by: java.net.ConnectException: Operation timed out",
      "  at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)",
      "  at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)",
      "  at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)",
      "  at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)",
      "  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:707)",
      "  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)",
      "  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)",
      "  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)",
      "  at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)",
      "  at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)",
      "  at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)",
      "  at java.base/java.lang.Thread.run(Thread.java:829)",
      ""
     ]
    }
   ],
   "source": [
    "var df_unit_minute = spark.read\n",
    "                        .option(\"header\", \"true\")\n",
    "                        .option(\"delimiter\", \";\")\n",
    "                        .csv(\"/Users/diakite/Downloads/mood_cashin_cashout_unit_minute_20230202_amanda.csv\")\n",
    "\n",
    "df_unit_minute.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5165d57-cb7f-46bd-bbf8-3dbccb5efe1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "2: error: '.' expected but identifier found.",
     "output_type": "error",
     "traceback": [
      "<console>:2: error: '.' expected but identifier found.",
      "       import pandas as pd",
      "                     ^",
      ""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2bcb3-7af4-41cf-91ac-d8cbd1f3f7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
